Here is your detailed, up-to-date **`README.md` for the RETRIEVE pipeline** ‚Äî covering architecture, logic, design choices, error handling, and extensibility.

---

# üß† Agentic RAG: RETRIEVE Pipeline (Modular)

## ‚úÖ Overview

The RETRIEVE pipeline is part of a modular Agentic RAG system that retrieves relevant context chunks from a MongoDB Atlas Vector Store and synthesizes LLM-based answers. It supports both **GPT** and **Gemini** embeddings, and uses subject-specific routing, logging, and intelligent fallback mechanisms.

---

## üóÇÔ∏è Key Files & Responsibilities

| File                   | Purpose                                                               |
| ---------------------- | --------------------------------------------------------------------- |
| `retrieve_pipeline.py` | Main entrypoint for retrieving context & answering queries            |
| `retriever_factory.py` | Constructs subject-aware retrievers using embedding provider & config |
| `mongo_config.json`    | Routing + index config per subject (`profile`, `history`, `default`)  |
| `mongo_utils.py`       | Loads config and connects to MongoDB                                  |
| `log_utils.py`         | Logs RETRIEVE calls, purges old logs, throttles cleanup to once/day   |

---

## üîÑ End-to-End Flow

```text
User Query
   ‚îÇ
   ‚ñº
[detect_subject_from_query()] ‚Üí subject (e.g., 'profile')
   ‚îÇ
   ‚ñº
[get_retriever_model(subject, provider)] ‚Üí builds retriever using subject-specific index
   ‚îÇ
   ‚ñº
[retriever.invoke(query)] ‚Üí retrieves top-K matching chunks
   ‚îÇ
   ‚ñº
[synthesize_with_llm()] ‚Üí generates final answer using GPT-4
   ‚îÇ
   ‚ñº
[log_retrieve_action()] ‚Üí stores log, triggers once-per-day cleanup
```

---

## ‚öôÔ∏è Intelligent Components

### üîç Subject Detection

* Based on keywords (`profile`, `history`, `index`, etc.)
* Falls back to `"default"` if no match

### üìö Retriever Factory

* Dynamically selects:

  * `collection_name`
  * `index_name`
  * `embedding provider`
* Uses `text_key="chunk_text"` for MongoDB Atlas
* Handles embedding mismatch errors gracefully

### üßº Logging & Cleanup

* Logs every RETRIEVE event with query, subject, match count
* Daily cleanup runs **only once per day**
* Controlled via in-memory `_last_cleanup_date`

---

## üß™ Error Handling

| Scenario                     | Behavior                                                     |
| ---------------------------- | ------------------------------------------------------------ |
| Embedding dimension mismatch | Detects vector size error and raises a friendly RuntimeError |
| Invalid subject              | Falls back to `default` if available, else raises ValueError |
| Zero matches                 | Returns graceful fallback from prompt synthesis              |
| MongoDB unreachable          | Raises connection error as-is (fail-fast)                    |

---

## ‚ö†Ô∏è Warnings/Deprecations

* `.get_relevant_documents()` was replaced with `.invoke()` to support LangChain >= v0.1.46
* `OpenAIEmbeddings` is deprecated in older import paths ‚Äî now using `langchain_openai`

---

## üìÅ Config Format (`mongo_config.json`)

```json
"profile": {
  "db_name": "agentic_rag",
  "collection_name": "Profile_DB",
  "index_name": "vector_index_profile_db",
  "top_k": 3
},
"default": {
  "collection_name": "Misc_DB",
  "index_name": "vector_index_misc_db"
}
```

Add separate `index_name_gpt` and `index_name_gemini` if using dual-index architecture.

---

## üß∞ How to Extend

| Task                              | Approach                                                                         |
| --------------------------------- | -------------------------------------------------------------------------------- |
| Add new subject (e.g. "projects") | Add config block in `mongo_config.json` and extend `detect_subject_from_query()` |
| Support more embedding providers  | Add logic in `retriever_factory.py`                                              |
| Persist log cleanup state         | Save `_last_cleanup_date` to file/DB instead of memory                           |
| Add quality testing               | Create `retrieve_quality_tester.py` to track match scores & chunk diversity      |

---

## ‚úÖ Ready to Use

You can now:

* Call `retrieve_answer(query, subject_hint=None)` from anywhere
* Switch embedding providers by setting: `EMBEDDING_PROVIDER=gpt` or `gemini`
* Monitor logs in MongoDB (`agentic_rag_logs.retrieve_logs`)
* Run tests using `Test_RETRIEVE_with_Embedding_Switch.py`

---

Let me know if you want this saved as a `README.md` file or added to a documentation page.
